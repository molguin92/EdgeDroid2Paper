\section{Discussion}\label{sec:discussion}

\subsection{Applicability of results to other \gls{MAR} applications}
\todo[inline]{TODO}

% \todo[inline]{%
%     Ergo we need a second order model. Everything that comes afterwards is only with second order model. Play with RTT.
% }


% .as well as an additional setup with \num{10} clients during which an instance of the \emph{iperf3}\footnote{\href{https://iperf.fr/}{https://iperf.fr/}} network load generator is also running on each client.
% The \emph{iperf3} instances each generate \SI{1.5}{Mbps} of upstream \gls{TCP} traffic, further congesting the wireless network.

\subsubsection{Optimizing for expected number of samples}

\todo[inline]{Rework}

We first look at the application of \cref{eq:epsilon_terminal} and its solution in \cref{eq:tnRayleigh} to the optimization of number of captured samples per step.
We start with this metric as its implications for resource consumption and responsiveness are straightforward to understand.
On the one hand, higher sampling rates directly lead to perceived increased system responsiveness, as smaller sampling intervals translate into smaller maximum wait times.
On the other, the relationship between number of samples captured and sent and network congestion is generally understood to be exponential-like, and too high sampling rates quickly lead to bottlenecks on the network, particularly in multi-tenant environments.
Additionally, the energy cost of capturing a sample on a \gls{WCA} client device is often much higher than remaining in an idle state, and thus excessive sampling leads to drastically increased energy consumption.
Optimizing the number of samples captured per step can thus be a straightforward way of reducing resource consumption and contention in \gls{WCA} applications.

However, an unconstrained optimization of the number of samples is trivial and meaningless as the solution points to a single sample at $t\!\rightarrow\!\infty$, taking the wait time to infinity.
Thus, we look at the constrained optimization of the expected number of samples with an upper bound $w_0$ for the expected wait.
That is, $\mathbb{E}[\mathcal{W}]\!\leq\!w_0$.

First note that the general solution has constants $\alpha$ and $\beta$ corresponding to the weights given to the cost of sampling and waiting, respectively.
The optimization criteria changes from minimizing wait time to minimizing the number of samples when the ratio $\frac{\alpha}{\beta}$ goes from zero to infinity.
Since any positive real value is valid for this ratio, one can achieve any valid points $(\mathbb{E}[\mathcal{S}],\mathbb{E}[\mathcal{W}])$ via simply by varying the ratio $\frac{\alpha}{\beta}$.

Furthermore, since the sampling instants are aperiodic and can take any positive real values, the bound will be tight at the optimum. 
% This is because (1) a higher bound on $\mathbb{\mathcal{W}}$ is always associated with a lower optimum on $\mathbb{\mathcal{S}}$ and (2) any $\mathbb{\mathcal{W}}$ can be achieved, for instance by a scaling all the sampling instance of a given policy by an appropriate constant.
Hence, to solve for the modified optimization problem that minimizes $\mathbb{E}[\mathcal{S}]$ with an upper bound $w_0$ on $\mathbb{E}[\mathcal{W}]$, we equate \cref{eq:Ew} to $w_0$, find the corresponding $\frac{\alpha}{\beta}$, and find the optimum set of sampling instants by plugging this ratio into \cref{eq:tnRayleigh}.
\begin{alignat*}{1}
\mathbb{E}[\mathcal{W}]&=\int_{0}^{\infty}\dfrac{1}{2r(t)}f_\mathcal{T}(t)\,\mathrm{d}t.\nonumber\\
&=\int_{0}^{\infty}\frac{1}{2}\sqrt{\frac{2\alpha\sigma^2}{\beta t}}\cdot \frac{t}{\sigma^2}e^{-{t^2}/{2\sigma^2}}\mathrm{d}t\\
&=\sqrt{\frac{\alpha\sigma^2}{2\beta}}\int_{0}^{\infty}\frac{\sqrt{t}}{\sigma^2}e^{-{t^2}/{2\sigma^2}}\mathrm{d}t\\
&=\sqrt{\frac{\alpha\sigma^2}{2\beta}}\left({\frac{1}{{2}\sigma^2}}\right)^{1/4}\cdot\int_{0}^{\infty}y^{-1/4}e^{-y}\mathrm{d}y\\
&=\sqrt{\frac{\alpha\sigma^2}{2\beta}}\left({\frac{1}{{2}\sigma^2}}\right)^{1/4}\cdot\mathlarger{\Gamma}(\tfrac{3}{4}),\\
% &\approx 0.728637\sqrt{\frac{\alpha\sigma}{\beta}}\\
\intertext{%
    where $\mathlarger{\Gamma(x)}$ is the gamma function.
    Thus, when the upper bound $w_0$ is tight,
}
\mathbb{E}[\mathcal{W}]&=w_0=\sqrt{\frac{\alpha\sigma}{2\sqrt{2}\beta}}\mathlarger{\Gamma}(\tfrac{3}{4})\\
\Rightarrow\frac{\alpha}{\beta}&=\frac{w_0^2}{\sigma}\frac{2\sqrt{2}}{(\mathlarger{\Gamma}(\tfrac{3}{4}))^2}\\
% &=1.88355\frac{w_0^2}{\sigma}
&\approx1.9\frac{w_0^2}{\sigma}.
\end{alignat*}
Plugging this into \cref{eq:tnRayleigh}, leaves us with the following expression for the optimal aperiodic sampling intervals when optimizing for number of samples
\begin{alignat}{1}
    t_n&=\Big(3\sigma\!\sqrt{\tfrac{\alpha}{2\beta}}\Big)^{\frac{2}{3}}n^{\frac{2}{3}}\nonumber\\
    &=\Big(3\sigma\!\sqrt{\tfrac{1.9w_0^2}{2\sigma} }\Big)^{\frac{2}{3}}n^{\frac{2}{3}}\;\blacksquare\label{eq:tnRayleigh:samples}
\end{alignat}